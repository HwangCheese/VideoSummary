import torch
import h5py
import numpy as np
import torchvision.models as models
import torchvision.transforms as transforms
import os
import json
from sklearn.decomposition import PCA
from decord import VideoReader, cpu
from PIL import Image
from transnetv2 import TransNetV2

# Inception V3 ë¡œë“œ
def load_inception_v3(device):
    print("ğŸ“¦ InceptionV3 ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = models.inception_v3(weights="DEFAULT")
    model.fc = torch.nn.Identity()
    return model.to(device).eval()

# íŠ¹ì§• ì¶”ì¶œ batch_sizeë¥¼ ëŠ˜ë¦¬ë©´ í›¨ì”¬ ì†ë„ê°€ ë¹¨ë¼ì§ˆê²ƒ 2^n ê°’ìœ¼ë¡œ ìœ ì§€
def extract_features(video_path, model, device, batch_size=32):
    print("ğŸï¸ í”„ë ˆì„ íŠ¹ì§• ì¶”ì¶œ ì¤‘... (Decord + ë°°ì¹˜ ì²˜ë¦¬, ë©”ëª¨ë¦¬ ìµœì í™”)")
    ctx = cpu(0)
    vr = VideoReader(video_path, ctx=ctx)
    fps = vr.get_avg_fps()
    frame_idxs = list(range(0, len(vr), int(round(fps))))

    transform = transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])

    feats = []
    batch = []
    for i, idx in enumerate(frame_idxs):
        frame = vr[idx].asnumpy()
        img = Image.fromarray(frame)
        batch.append(transform(img))

        # âœ… í”„ë ˆì„ ì²˜ë¦¬ ì§„í–‰ ìƒí™© ì¶œë ¥
        print(f"ğŸ“¸ ì²˜ë¦¬ ì¤‘... {idx}/{len(vr)} í”„ë ˆì„", flush=True)

        if len(batch) == batch_size or i == len(frame_idxs) - 1:
            tensor_batch = torch.stack(batch).to(device)
            with torch.no_grad():
                batch_feats = model(tensor_batch).cpu().numpy()
                feats.append(batch_feats)
            batch = []

    return np.concatenate(feats, axis=0)

# PCA ì ìš©
def apply_pca(features, max_components=1024):
    n_samples = features.shape[0]
    n_components = min(n_samples, max_components)
    if n_samples < 2:
        return features
    pca = PCA(n_components=n_components)
    pca_features = pca.fit_transform(features)
    if n_components < max_components:
        pca_features = np.pad(pca_features, ((0, 0), (0, max_components - n_components)))
    return pca_features

# íŠ¹ì§• ì €ì¥
def save_to_h5(features, output_h5):
    os.makedirs(os.path.dirname(output_h5), exist_ok=True)
    with h5py.File(output_h5, "w") as hf:
        hf.create_dataset("features", data=features)

# TransNetV2ë¥¼ ì´ìš©í•œ ì¥ë©´ ì „í™˜ ê°ì§€
def detect_scenes_transnetv2(video_path, threshold=0.5):
    print("ğŸ¬ TransNetV2ë¡œ ì¥ë©´ ì „í™˜ ê°ì§€ ì¤‘...")
    model = TransNetV2()
    video_frames, single_frame_predictions, _ = model.predict_video(video_path)
    scene_changes = np.where(single_frame_predictions > threshold)[0]
    print(f"âœ… {len(scene_changes)}ê°œì˜ ì¥ë©´ ì „í™˜ì  ê²€ì¶œ ì™„ë£Œ")
    return scene_changes.tolist(), video_frames.shape[0]

# ì¥ë©´ êµ¬ê°„ JSONìœ¼ë¡œ ì €ì¥
def save_segments_to_json(scene_changes, output_json, total_frames, fps):
    segment_data = []
    scene_changes = [0] + scene_changes + [total_frames - 1]
    for idx in range(len(scene_changes)-1):
        start_frame = scene_changes[idx]
        end_frame = scene_changes[idx+1]
        segment_data.append({
            "segment_id": idx,
            "start_time": round(start_frame / fps, 2),
            "end_time": round(end_frame / fps, 2)
        })

    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(segment_data, f, ensure_ascii=False, indent=4)
    print("âœ… ì¥ë©´ êµ¬ê°„ JSON ì €ì¥ ì™„ë£Œ")

# íŠ¹ì§• ì¶”ì¶œ ë° TransNetV2 ì¥ë©´ ë¶„í•  íŒŒì´í”„ë¼ì¸
def extract_features_pipe(video_path, output_h5, output_json, device="cuda"):
    os.makedirs(os.path.dirname(output_h5), exist_ok=True)
    os.makedirs(os.path.dirname(output_json), exist_ok=True)

    model = load_inception_v3(device)
    features = extract_features(video_path, model, device)
    pca_features = apply_pca(features)
    save_to_h5(pca_features, output_h5)

    scene_changes, total_frames = detect_scenes_transnetv2(video_path)
    fps = VideoReader(video_path, cpu(0)).get_avg_fps()
    save_segments_to_json(scene_changes, output_json, total_frames, fps)

    print("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
