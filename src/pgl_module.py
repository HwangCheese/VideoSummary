# pgl_module.py
import torch
import json
import numpy as np
import h5py
import os
from networks.pgl_sum.pgl_sum import PGL_SUM
from knapsack_module import run_sub_knapsack_pipeline

def load_h5_features(h5_path):
    """H5 íŒŒì¼ì—ì„œ í”„ë ˆì„ íŠ¹ì§•(feature)ì„ ë¡œë“œ"""
    with h5py.File(h5_path, "r") as hf:
        return np.array(hf["features"])

def predict_scores(model, features, device="cpu"):
    """ëª¨ë¸ì„ í†µí•´ í•˜ì´ë¼ì´íŠ¸ ì ìˆ˜ë¥¼ ì˜ˆì¸¡"""
    x = torch.from_numpy(features).float().to(device)
    if x.ndim == 2:
        x = x.unsqueeze(0)
    mask = torch.ones((x.shape[0], x.shape[1]), dtype=torch.bool).to(device)
    with torch.no_grad():
        scores, _ = model(x, mask)
    scores = scores.cpu().numpy().squeeze()
    print(f"ğŸ“Š ìš”ì•½ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸: {scores} ê¸¸ì´: {len(scores)}")
    return scores

def load_model_checkpoint(model, ckpt_path, device):
    """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ"""
    checkpoint = torch.load(ckpt_path, map_location=device)
    if "model_state_dict" in checkpoint:
        model.load_state_dict(checkpoint["model_state_dict"], strict=False)
    else:
        model.load_state_dict(checkpoint, strict=False)
    return model


def load_scene_segments(scene_json, fps, thr=0.5):
    """
    ì¤‘ë³µ ì—†ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ë¡œë“œ (ë¹„ì •ìƒ ì„¸ê·¸ë¨¼íŠ¸ëŠ” invalidë¡œ ì²˜ë¦¬)
    """
    with open(scene_json, "r") as f:
        segments = json.load(f)

    for seg in segments:
        seg["start_frame"] = int(seg["start_time"] * fps)

    for i, seg in enumerate(segments):
        if i < len(segments) - 1:
            next_seg = segments[i + 1]
            boundary_frame = next_seg["start_frame"]

            frac = seg["end_time"] - int(seg["end_time"])
            
            if frac < thr:
                seg["end_frame"] = boundary_frame - 1
            else:
                seg["end_frame"] = boundary_frame
                next_seg["start_frame"] = boundary_frame + 1
        else:
            seg["end_frame"] = int(seg["end_time"] * fps) - 1

        # ğŸ”¥ ë³´ì • ëŒ€ì‹  ë¹„ì •ìƒ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ì œê±° ëŒ€ìƒ(invalid) ë§ˆí‚¹
        seg["invalid"] = seg["end_frame"] < seg["start_frame"]

    return segments


def save_segment_frame_scores_json(scores, scene_segments, output_json, fps):
    """
    í”„ë ˆì„ ì ìˆ˜ JSON ì €ì¥ (invalid ì„¸ê·¸ë¨¼íŠ¸ ì œì™¸)
    """
    segment_scores = []

    for seg in scene_segments:
        if seg.get("invalid", False):
            print(f"âš ï¸ Invalid segment_id={seg['segment_id']} (start_frame={seg['start_frame']} end_frame={seg['end_frame']}) Skipped.")
            continue  # invalid ì„¸ê·¸ë¨¼íŠ¸ ì œì™¸

        start_frame = seg["start_frame"]
        end_frame = min(seg["end_frame"], len(scores) - 1)

        if start_frame >= len(scores):
            continue

        frame_scores = scores[start_frame: end_frame + 1]
        if len(frame_scores) == 0:
            continue

        avg_score = float(np.mean(frame_scores))
        max_score = float(np.max(frame_scores))
        std_score = float(np.std(frame_scores))

        segment_scores.append({
            "segment_id": seg["segment_id"],
            "start_time": seg["start_time"],
            "end_time": seg["end_time"],
            "frame_scores": frame_scores.tolist(),
            "avg_score": avg_score,
            "max_score": max_score,
            "std_score": std_score
        })

    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(segment_scores, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“„ Segment scores JSON saved: {output_json}")
    return segment_scores

def save_sorted_segments_with_combined_score_json(segment_scores, alpha, std_weight, output_json):
    """
    ê° ì„¸ê·¸ë¨¼íŠ¸ì— ê°€ì¤‘í•©(combined_score)ì„ ê³„ì‚°í•œ í›„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì €ì¥
    """
    for seg in segment_scores:
        seg["combined_score"] = (seg["avg_score"] * alpha) + (seg["max_score"] * (1 - alpha)) - (std_weight * seg["std_score"])
    sorted_segments = sorted(segment_scores, key=lambda x: x["combined_score"], reverse=True)
    with open(output_json, "w") as f:
        json.dump(sorted_segments, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“„ Sorted segments JSON saved (combined_score): {output_json}")
    return sorted_segments

# def save_segment_frame_ranges_json(scene_segments, segment_scores, fps, output_path):
#     """
#     ì„¸ê·¸ë¨¼íŠ¸ì˜ í”„ë ˆì„ ë²”ìœ„, ì‹œê°„ ë° ê°€ì¤‘í•© ì ìˆ˜ë¥¼ ì €ì¥
#     """
#     combined_score_dict = {seg["segment_id"]: seg.get("combined_score", None) for seg in segment_scores}
#     frame_ranges = []
#     for seg in scene_segments:
#         start_frame = int(seg["start_time"] * fps)
#         end_frame = int(seg["end_time"] * fps)
#         combined_score = combined_score_dict.get(seg["segment_id"])
#         frame_ranges.append({
#             "segment_id": seg["segment_id"],
#             "start_frame": start_frame,
#             "end_frame": end_frame,
#             "combined_score": round(combined_score, 5) if combined_score is not None else None,
#             "start_time": seg["start_time"],
#             "end_time": seg["end_time"]
#         })
#     with open(output_path, "w") as f:
#         json.dump(frame_ranges, f, indent=2, ensure_ascii=False)
#     print(f"ğŸ“„ ì„¸ê·¸ë¨¼íŠ¸ í”„ë ˆì„ + ì‹œê°„ ë²”ìœ„ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
#     return frame_ranges

# def run_pgl_pipeline(

def run_pgl_module(
    ckpt_path,
    feature_h5,
    scene_json,
    output_json,
    output_sorted_combined_json,
    fps=1.0,
    device="cpu",
    alpha=0.7,
    std_weight=0.3,
    top_ratio=0.2,
    importance_weight=0.8,
    budget_time=None):

    print(f"ğŸš€ ë””ë°”ì´ìŠ¤: {device}")

# video_pathë¡œë¶€í„° base_filename (ì˜ˆ: "shortbox") ê²°ì •
    # base_filename = os.path.splitext(os.path.basename(args.video_path))[0]
    # os.makedirs(f"./{base_filename}", exist_ok=True)

    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    # output_json_path = f"./{base_filename}/{base_filename}_segment_scores.json"
    # output_sorted_combined_json_path = f"./{base_filename}/{base_filename}_sorted_combined.json"
    # segment_frame_json_path = f"./{base_filename}/{base_filename}_segment_frame.json"
    # pgl íŒŒíŠ¸ì—ì„œ í•„ìš”í•œ scene ì„¸ê·¸ë¨¼íŠ¸ JSON íŒŒì¼ (ë¯¸ë¦¬ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•¨)
    # scene_json_path = f"./{base_filename}/{base_filename}_scenes.json"

    # ëª¨ë¸ ì´ˆê¸°í™” ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    
    model = PGL_SUM(input_size=1024, output_size=1024, num_segments=4, heads=8, fusion="add", pos_enc="absolute")
    model = load_model_checkpoint(model, ckpt_path, device)
    model.to(device).eval()

    features = load_h5_features(feature_h5)
    scores = predict_scores(model, features, device=device)

    scene_segments = load_scene_segments(scene_json, fps, thr=0.5)
    segment_scores = save_segment_frame_scores_json(scores, scene_segments, output_json, fps)
    save_sorted_segments_with_combined_score_json(segment_scores, alpha, std_weight, output_sorted_combined_json)

    selected_segments = run_sub_knapsack_pipeline(feature_h5, scene_json, fps, output_sorted_combined_json, importance_weight, top_ratio, budget_time)
    return selected_segments
