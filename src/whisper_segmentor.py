import whisper
import torchaudio
import torch
import json


def process(audio_path, scene_json_path, output_json_path, model_size="small"):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ë””ë°”ì´ìŠ¤: {device} (Silero VAD + Whisper {model_size})")

    # Silero VAD ë¡œë“œ ë° ìŒì„± êµ¬ê°„ ì¶”ì¶œ (trust_repo=True ëª…ì‹œ)
    vad_model, utils = torch.hub.load(
        repo_or_dir='snakers4/silero-vad',
        model='silero_vad',
        trust_repo=True
    )
    get_speech_timestamps, _, read_audio, *_ = utils
    audio_tensor = read_audio(audio_path, sampling_rate=16000).to(device)

    # ğŸ”§ VAD ë¯¼ê°ë„ ì¡°ì •
    vad_segments = get_speech_timestamps(
        audio_tensor, vad_model,
        threshold=0.3,
        min_speech_duration_ms=100
    )
    vad_time_ranges = [(s['start'] / 16000, s['end'] / 16000) for s in vad_segments]

    # Whisper ìŒì„± ì¸ì‹ ìˆ˜í–‰
    model = whisper.load_model(model_size).to(device)

    # ì–¸ì–´ ìë™ ê°ì§€ (tiny ëª¨ë¸ ì œì™¸)
    if model_size != "tiny":
        audio = whisper.load_audio(audio_path)
        audio = whisper.pad_or_trim(audio)
        mel = whisper.log_mel_spectrogram(audio).to(device)
        _, probs = model.detect_language(mel)
        detected_lang = max(probs, key=probs.get)
        print(f"ê°ì§€ëœ ì–¸ì–´: {detected_lang}")

        # í•œêµ­ì–´/ì˜ì–´ ì™¸ì˜ ì–¸ì–´ë©´ fallback
        if detected_lang not in ["ko", "en"]:
            print(f"ê°ì§€ëœ ì–¸ì–´({detected_lang})ê°€ ë¹„ì •ìƒì ì…ë‹ˆë‹¤. ì˜ì–´(en)ë¡œ ê°•ì œ ì§€ì •í•©ë‹ˆë‹¤.")
            detected_lang = "en"
    else:
        detected_lang = None

    result = model.transcribe(audio_path, language=detected_lang)

    # Whisper ìë§‰ ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš© ì¶œë ¥
    print(f"Whisper ì¶”ì¶œ ìë§‰ ìˆ˜: {len(result['segments'])}")

    # Whisper ìë§‰ ê²°ê³¼ì—ì„œ ìœ íš¨í•œ ìŒì„± êµ¬ê°„ë§Œ í•„í„°ë§
    filtered_segments = []
    for seg in result['segments']:
        w_start, w_end = seg['start'], seg['end']
        for v_start, v_end in vad_time_ranges:
            if w_start <= v_end and w_end >= v_start:
                filtered_segments.append({
                    "start": round(w_start, 2),
                    "end": round(w_end, 2),
                    "text": seg['text'].strip()
                })
                break

    if not filtered_segments:
        print("VAD í•„í„°ë§ëœ ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤. Whisper ì „ì²´ ìë§‰ì„ ì €ì¥í•©ë‹ˆë‹¤.")
        filtered_segments = [
            {
                "start": round(seg['start'], 2),
                "end": round(seg['end'], 2),
                "text": seg['text'].strip()
            }
            for seg in result['segments']
        ]

    # JSON ì €ì¥
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(filtered_segments, f, indent=2, ensure_ascii=False)

    print(f"Whisper ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥ ì™„ë£Œ: {output_json_path}")