# knapsack_module.py
import json
import numpy as np
import h5py
from sklearn.metrics.pairwise import cosine_similarity

def load_file(json_filename):
    """JSON íŒŒì¼ì„ ë¡œë“œ"""
    with open(json_filename, 'r') as f:
        segments = json.load(f)
    return segments

def get_segment_average_vectors(h5_filename, segments, fps):
    """
    H5 íŒŒì¼ì—ì„œ í”„ë ˆì„ featureë¥¼ ë¶ˆëŸ¬ì™€ì„œ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ í‰ê·  ë²¡í„°ë¥¼ ê³„ì‚°
    """
    with h5py.File(h5_filename, 'r') as f:
        features = f['features'][:]  # shape: (num_frames, feature_dim)
    segment_avg_dict = {}
    for seg in segments:
        start_time = seg['start_time']
        end_time = seg['end_time']
        start_frame = int(start_time * fps)
        end_frame = int(end_time * fps)
        seg_vector = np.mean(features[start_frame:end_frame+1], axis=0)
        segment_avg_dict[seg['segment_id']] = seg_vector
    return segment_avg_dict

def greedy_submodular_knapsack_selection(segment_ids, segment_vectors, importance, sorted_combined, budget_time, weight=1.0):
    """
    ê·¸ë¦¬ë”” ë°©ì‹ì˜ ì„œë¸Œëª¨ë“ˆëŸ¬ + Knapsack ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ ì•Œê³ ë¦¬ì¦˜.
    ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹œê°„(ë¹„ìš©)ê³¼ ì¤‘ìš”ë„(combined_score)ë¥¼ ê³ ë ¤í•˜ì—¬ ì„ íƒ.
    """
    N = segment_vectors.shape[0]
    # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ì§€ì† ì‹œê°„(ì´ˆ)
    cost = np.array([seg["end_time"] - seg["start_time"] for seg in sorted_combined])
    sim_matrix = cosine_similarity(segment_vectors)
    current_coverage = np.zeros(N)
    selected = []
    total_time = 0.0

    while True:
        best_gain = -np.inf
        best_candidate = None
        best_candidate_cost = None

        for j in range(N):
            if j in selected:
                continue

            candidate_cost = cost[j]
            if total_time + candidate_cost > budget_time:
                continue

            if weight == 1.0:
                candidate_gain = importance[j] / candidate_cost
                # print(f"  - ID: {j}, ì ìˆ˜: {candidate_gain:.4f}")

            else:
                # ì¤‘ìš”ë„ì™€ ë‹¤ì–‘ì„±ì„ ê²°í•©í•œ gain ê³„ì‚°
                score_gain = importance[j]
                diversity_gain_sum = 0.0
                for i in range(N):
                    prev_cov = current_coverage[i]
                    new_cov = max(prev_cov, sim_matrix[i, j])
                    delta = new_cov - prev_cov
                    diversity_gain_sum += importance[i] * delta
                diversity_gain = diversity_gain_sum / candidate_cost if candidate_cost > 0 else 0.0
                candidate_gain = weight * (score_gain / candidate_cost) + (1 - weight) * diversity_gain

            if candidate_gain > best_gain:
                best_gain = candidate_gain
                best_candidate = j
                best_candidate_cost = candidate_cost

        if best_candidate is None:
            break

        selected.append(best_candidate)
        total_time += best_candidate_cost
        print(f"  - segment ID: {segment_ids[best_candidate]}, ì ìˆ˜: {best_gain:.4f}")
        if weight != 1.0:
            for i in range(N):
                current_coverage[i] = max(current_coverage[i], sim_matrix[i, best_candidate])

    selected_ids = [segment_ids[j] for j in selected]
    return selected_ids, total_time

def run_sub_knapsack_pipeline(feature_h5, scene_json, fps, output_sorted_combined_json, importance_weight, top_ratio=None, budget_time=None):
    """
    pgl_moduleì—ì„œ ìƒì„±í•œ ì„¸ê·¸ë¨¼íŠ¸ í”„ë ˆì„ ë²”ìœ„ JSON íŒŒì¼ê³¼ feature íŒŒì¼ì„ ì´ìš©í•´
    Submodular + Knapsack ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒì„ ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜.
    
    ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ IDë“¤ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ë©”ëª¨ë¦¬ ë‚´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """

    # h5_file = args.feature_h5  # pgl_moduleì—ì„œ ì‚¬ìš©í•œ feature íŒŒì¼ê³¼ ë™ì¼
    # output_h5_path = f"./features/{base_filename}.h5"
    # output_id_path = f"./{base_filename}/{base_filename}_selected_segmentID.json"
    
    # scenes_file = f'./{base_filename}/{base_filename}_scenes.json'
    scenes = load_file(scene_json)
    segment_avg_dict = get_segment_average_vectors(feature_h5, scenes,fps)

    segment_ids = []
    segment_vectors = []
    importance = []
    
    # sorted_combined_file = f'./{base_filename}/{base_filename}_sorted_combined.json'
    sorted_combined = load_file(output_sorted_combined_json)

    for seg in sorted_combined:
        seg_id = seg['segment_id']
        segment_ids.append(seg_id)
        segment_vectors.append(segment_avg_dict[seg_id])
        importance.append(seg.get("combined_score", 0.0))
    segment_vectors = np.array(segment_vectors)
    importance = np.array(importance)

    # video_length = max(seg["end_time"] for seg in scenes)
    # budget_time = video_length * 0.2
    # print("ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ):", video_length)
    # print("ìš”ì•½ ì˜ˆì‚° (20%):", budget_time)

    if budget_time is None and top_ratio is None:
        raise ValueError("top_ratio ë˜ëŠ” budget_time ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

    video_length = max(seg['end_time'] for seg in scenes)

    if budget_time is None:
        budget_time = video_length * top_ratio
        print(f"ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ): {video_length:.2f}")
        print(f"top_ratio ê¸°ë°˜ ì˜ˆì‚° (ì´ˆ): {budget_time:.2f}")
    else:
        print(f"ì‚¬ìš©ì ì§€ì • ì˜ˆì‚° ì‹œê°„ (ì´ˆ): {budget_time:.2f}")
    
    selected_ids, used_time = greedy_submodular_knapsack_selection(
        segment_ids, segment_vectors, importance, sorted_combined, budget_time, weight=importance_weight
    )

    print("ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸:", selected_ids)
    print("ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ì´ ì‹œê°„ (ì´ˆ):", used_time)

    # with open(output_id_path, "w") as f:
    #     json.dump(selected_ids, f, indent=2)
    # print(f"ğŸ’¾ ì„ íƒëœ ì„¸ê·¸ë¨¼íŠ¸ ID ì €ì¥ë¨ (JSON): {output_id_path}")
    
    # selected_ids â†’ ì‹¤ì œ segment ê°ì²´ë“¤ë¡œ ë³€í™˜
    selected_segments = [seg for seg in sorted_combined if seg["segment_id"] in selected_ids]
    return selected_segments
