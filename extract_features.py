import argparse
import h5py
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
from sklearn.decomposition import PCA
import json
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector
import concurrent.futures  # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# âœ… Inception-v3 ëª¨ë¸ ë¡œë“œ (GPU device ì‚¬ìš©)
def load_inception_v3(device):
    model = models.inception_v3(weights="DEFAULT")
    model.fc = torch.nn.Identity()
    model = model.to(device).eval()
    return model

# âœ… íŠ¹ì§• ì¶”ì¶œ (1ì´ˆì— 1í”„ë ˆì„)
def extract_features(video_path, model, device):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30

    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])

    features = []
    frame_count = 0

    success, frame = cap.read()
    while success:
        # 1ì´ˆì— í•œ í”„ë ˆì„ ì²˜ë¦¬
        if frame_count % round(fps) == 0:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            tensor = transform(frame_rgb).unsqueeze(0).to(device)
            with torch.no_grad():
                feat = model(tensor).cpu().numpy().squeeze()
                features.append(feat)
        success, frame = cap.read()
        frame_count += 1

    cap.release()
    return np.array(features)

# âœ… PCA ì ìš©
def apply_pca(features, max_components=1024):
    n_samples, n_features = features.shape
    n_components = min(n_samples, max_components)
    print(f"\U0001F4CC PCA ì ìš© ì¤‘... (ì›ë˜ {n_features}D â†’ {n_components}D)")

    if n_samples < 2:
        print("âš ï¸ ìƒ˜í”Œì´ ë„ˆë¬´ ì ì–´ PCA ë¶ˆê°€, ì›ë³¸ ìœ ì§€")
        return features

    pca = PCA(n_components=n_components)
    pca_features = pca.fit_transform(features)

    if n_components < max_components:
        pad_width = ((0, 0), (0, max_components - n_components))
        pca_features = np.pad(pca_features, pad_width, mode='constant', constant_values=0)

    return pca_features

# âœ… íŠ¹ì§•ì„ HDF5ë¡œ ì €ì¥
def save_to_h5(features, output_h5):
    with h5py.File(output_h5, "w") as hf:
        hf.create_dataset("features", data=features)
    print(f"âœ… íŠ¹ì§• ì €ì¥ ì™„ë£Œ: {output_h5} (shape={features.shape})")

# âœ… ì¥ë©´ ì»· ê°ì§€
def detect_scenes(video_path, threshold=27.0, min_scene_len=45):
    video_manager = VideoManager([video_path])
    scene_manager = SceneManager()
    scene_manager.add_detector(ContentDetector(threshold=threshold, min_scene_len=min_scene_len))

    print(f"\U0001F4FC ì˜ìƒ ë¡œë”© ì¤‘: {video_path}")
    video_manager.set_downscale_factor()
    video_manager.start()
    scene_manager.detect_scenes(frame_source=video_manager)

    scene_list = scene_manager.get_scene_list()
    fps = video_manager.get_framerate()

    print(f"âœ… ì¥ë©´ ì»· ê°ì§€ ì™„ë£Œ: ì´ {len(scene_list)}ê°œ")

    change_points = []
    for start_time, end_time in scene_list:
        start_frame = int(start_time.get_frames())
        end_frame = int(end_time.get_frames()) - 1
        change_points.append([start_frame, end_frame])
    return change_points, fps

# âœ… JSON ì €ì¥
def save_segments_to_json(change_points, output_json, fps):
    segment_data = []
    for idx, (start, end) in enumerate(change_points):
        segment_info = {
            "segment_id": idx,
            "start_time": round(start / fps, 2),
            "end_time": round(end / fps, 2)
        }
        segment_data.append(segment_info)

    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(segment_data, f, ensure_ascii=False, indent=4)
    print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_json}")
    print(f"  - segments: {len(segment_data)}")

# âœ… GPU ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ (ë°°ì¹˜, PCA, ì €ì¥)
def run_feature_extraction(args, device):
    model = load_inception_v3(device)
    raw_features = extract_features(args.video_path, model, device)
    print(f"âœ… ì›ë³¸ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ (shape): {raw_features.shape}")

    pca_features = apply_pca(raw_features, max_components=1024)
    print(f"âœ… PCA ì™„ë£Œ (shape): {pca_features.shape}")

    save_to_h5(pca_features, args.output_h5)

# âœ… CPU ê¸°ë°˜ ì¥ë©´ ê°ì§€ íŒŒì´í”„ë¼ì¸ (JSON ì €ì¥)
def run_scene_detection(args):
    change_points, fps = detect_scenes(
        args.video_path,
        threshold=args.threshold,
        min_scene_len=args.min_scene_len
    )
    save_segments_to_json(change_points, args.output_json, fps)

# âœ… ë©”ì¸ í•¨ìˆ˜: GPUì™€ CPUë¥¼ ë³‘ë ¬ë¡œ ì‚¬ìš©
def main(args):
    # ì‚¬ìš©ìê°€ GPUë¡œ ì§€ì •í•œ device(ì˜ˆ: "cuda:1") ì‚¬ìš©. ì—†ìœ¼ë©´ CPU
    device = torch.device(args.gpu_device if torch.cuda.is_available() else "cpu")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {device}")
    if torch.cuda.is_available():
        print("GPU name:", torch.cuda.get_device_name(0))
        print("GPU count:", torch.cuda.device_count())
    else:
        print("âŒ CUDA not available. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•´ íŠ¹ì§• ì¶”ì¶œê³¼ ì¥ë©´ ê°ì§€ë¥¼ ë³‘ë ¬ ì‹¤í–‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        future_feat = executor.submit(run_feature_extraction, args, device)
        future_scene = executor.submit(run_scene_detection, args)
        
        # ë‘ ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
        concurrent.futures.wait([future_feat, future_scene])
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--video_path", required=True, help="MP4 ë¹„ë””ì˜¤ ê²½ë¡œ")
    parser.add_argument("--output_h5", required=True, help="ì €ì¥í•  HDF5 ê²½ë¡œ")
    parser.add_argument("--output_json", required=True, help="ì €ì¥í•  JSON ê²½ë¡œ")
    parser.add_argument("--threshold", type=float, default=27.0, help="ì¥ë©´ ì „í™˜ ê°ì§€ ë¯¼ê°ë„")
    parser.add_argument("--min_scene_len", type=int, default=45, help="ìµœì†Œ ì¥ë©´ ê¸¸ì´ (í”„ë ˆì„)")
    # GPU device ì§€ì •: ì˜ˆë¥¼ ë“¤ì–´, GTX 1650 TIê°€ cuda:1ì´ë¼ë©´ "cuda:1"ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
    parser.add_argument("--gpu_device", default="cuda:0", help="GPU ë””ë°”ì´ìŠ¤ (ì˜ˆ: cuda:0). GPU ì‚¬ìš© ë¶ˆê°€ ì‹œ CPU ì‚¬ìš©")
    args = parser.parse_args()
    main(args)